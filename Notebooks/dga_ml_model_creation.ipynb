{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r'C:/Users/ashuo/DNS/data/dga_classifier_data/normal_domain_names/opendns-top-domains.txt', header=None, names=['domain_name'])\n",
    "df2 = pd.read_csv(r'C:/Users/ashuo/DNS/data/dga_classifier_data/normal_domain_names/opendns-top-domains.txt', header=None, names=['domain_name'])\n",
    "df3 = pd.read_csv(r'C:/Users/ashuo/DNS/data/dga_classifier_data/normal_domain_names/non_malicious_domain_names.txt', header=None, names=['domain_name'])\n",
    "df3 = df3.drop_duplicates()\n",
    "df_normal = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "df_normal = df_normal.drop_duplicates()\n",
    "\n",
    "df_normal['source'] = 'open_dns'\n",
    "df_normal['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def sample_domains_from_files(directory, sample_size):\n",
    "    all_domains = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                domains = f.read().splitlines()\n",
    "                # Check if the file has enough domains to sample\n",
    "                if len(domains) >= sample_size:\n",
    "                    # Randomly sample domains from this file\n",
    "                    sampled_domains = random.sample(domains, sample_size)\n",
    "                    # Pair each sampled domain with the filename\n",
    "                    domains_with_source = [(domain, filename) for domain in sampled_domains]\n",
    "                    all_domains.extend(domains_with_source)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_domains, columns=['domain_name', 'source'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Use the function\n",
    "directory = r'C:/Users/ashuo/DNS/data/dga_classifier_data/dga_domain_names'  # replace with your actual directory\n",
    "sample_size = 275\n",
    "df_dga = sample_domains_from_files(directory, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dga.shape\n",
    "df_dga['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_normal, df_dga], ignore_index=True)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39793 entries, 0 to 39792\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   domain_name  39793 non-null  object\n",
      " 1   source       39793 non-null  object\n",
      " 2   label        39793 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 932.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#df = df.drop(['source'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import double\n",
    "import tldextract\n",
    "from collections import Counter\n",
    "import math\n",
    "from tld import get_tld\n",
    "\n",
    "dataset = []\n",
    "\n",
    "def calculate_entropy(domain):\n",
    "    # Count the frequency of each character in the domain\n",
    "    freq = Counter(domain)\n",
    "    \n",
    "    # Calculate the probability of each character\n",
    "    domain_length = double(len(domain))\n",
    "    probabilities = [float(freq[char]) / domain_length for char in set(domain)]\n",
    "    \n",
    "    # Calculate the entropy using the Shannon entropy formula\n",
    "    entropy = -sum(p * math.log2(p) for p in probabilities)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def calculate_average_entropy_of_subdomains(ext):\n",
    "\n",
    "    if ext.subdomain == '':\n",
    "        return 0.0\n",
    "    # Split the domain into subdomains using the dot separator\n",
    "    subdomains = ext.subdomain.split('.')\n",
    "    \n",
    "    # Calculate the entropy of each subdomain\n",
    "    subdomain_entropies = [calculate_entropy(sub) for sub in subdomains]\n",
    "    \n",
    "    # Calculate the average entropy of subdomains\n",
    "    avg_entropy = sum(subdomain_entropies)/double(len(subdomain_entropies))\n",
    "    \n",
    "    return avg_entropy\n",
    "\n",
    "def calculate_alphanumeric_ratio(domain):\n",
    "    # Count the number of alphanumeric characters (lowercase alphabetic or numeric)\n",
    "    alphanumeric_count = sum(1 for char in domain if char.isalnum() and char.islower())\n",
    "    \n",
    "    # Count the total number of characters in the domain\n",
    "    total_characters = double(len(domain))\n",
    "\n",
    "    alphanumeric_ratio = alphanumeric_count / total_characters\n",
    "    \n",
    "    return alphanumeric_ratio\n",
    "\n",
    "def count_number_of_subdomains(ext):\n",
    "    if ext.subdomain == '':\n",
    "        return 0.0\n",
    "\n",
    "    subdomains = ext.subdomain.split('.')\n",
    "\n",
    "    return len(subdomains)\n",
    "\n",
    "\n",
    "def calculate_average_subdomain_length(ext):\n",
    "    if ext.subdomain == '':\n",
    "        return 0.0\n",
    "    # Split the domain into subdomains using the dot separator\n",
    "    subdomains = ext.subdomain.split('.')\n",
    "\n",
    "    subdomains_to_consider = subdomains\n",
    "\n",
    "    # Calculate the length of each subdomain\n",
    "    subdomain_lengths = [len(sub) for sub in subdomains_to_consider]\n",
    "\n",
    "    avg_subdomain_length = sum(subdomain_lengths)/double(len(subdomain_lengths))\n",
    "\n",
    "    return avg_subdomain_length\n",
    "\n",
    "def calculate_numeric_ratio(domain):\n",
    "    # Calculate the number of numeric characters in the domain\n",
    "    numeric_count = double(sum(1 for char in domain if char.isdigit()))\n",
    "    \n",
    "    # Calculate the total length of the domain\n",
    "    total_length = double(len(domain))\n",
    "    \n",
    "    if(total_length == 0):\n",
    "        return 0.0\n",
    "    \n",
    "    numeric_ratio = numeric_count / total_length\n",
    "    \n",
    "    return numeric_ratio\n",
    "\n",
    "def calculate_special_char_ratio(domain):\n",
    "    # Count the number of special characters in the domain excluding '.'\n",
    "    special_char_count = sum(1 for char in domain if not (char.isalnum() or char == '.'))\n",
    "\n",
    "    # Calculate the total length of the domain excluding '.'\n",
    "    total_length_excluding_dot = double(len([char for char in domain if char != '.']))\n",
    "\n",
    "    # Calculate the special character ratio\n",
    "    if total_length_excluding_dot > 0:\n",
    "        special_char_ratio = double(special_char_count)/double(total_length_excluding_dot)\n",
    "    else:\n",
    "        special_char_ratio = 0.0  # Set ratio to 0 if the domain has no characters excluding '.'\n",
    "\n",
    "    return special_char_ratio\n",
    "\n",
    "def count_digits(domain):\n",
    "    # Initialize a counter for digits\n",
    "    digit_count = 0\n",
    "\n",
    "    # Iterate through each character in the domain name\n",
    "    for char in domain:\n",
    "        if char.isdigit():  # Check if the character is a digit\n",
    "            digit_count += 1  # Increment the counter for each digit found\n",
    "\n",
    "    return digit_count\n",
    "\n",
    "def count_hyphens(domain):\n",
    "    hyphen_count = 0\n",
    "\n",
    "    for char in domain:\n",
    "        if char == '-':  \n",
    "            hyphen_count += 1  \n",
    "\n",
    "    return hyphen_count\n",
    "\n",
    "def count_vowels(domain):\n",
    "    vowels = {'a', 'e', 'i', 'o', 'u'}\n",
    "    domain_lower = domain.lower()\n",
    "    vowel_count = sum(1 for char in domain_lower if char in vowels)\n",
    "    return vowel_count\n",
    "\n",
    "def calculate_repeated_chars_ratio(subdomain):\n",
    "    subdomain_lower = subdomain.lower()\n",
    "    total_chars = len(subdomain_lower)\n",
    "    unique_chars = len(set(subdomain_lower))\n",
    "    repeated_chars = total_chars - unique_chars\n",
    "    repeated_chars_ratio = double(repeated_chars)/total_chars if total_chars > 0 else 0.0\n",
    "\n",
    "    return repeated_chars_ratio\n",
    "\n",
    "def calculate_consecutive_digits_ratio(domain):\n",
    "    # Extract the domain part without the valid public suffix (TLD)\n",
    "    ext = tldextract.extract(domain)\n",
    "    domain_without_tld = ext.domain\n",
    "\n",
    "    # Convert the domain name to lowercase for consistency\n",
    "    domain_lower = domain_without_tld.lower()\n",
    "\n",
    "    # Initialize variables for counting consecutive digits and total characters\n",
    "    consecutive_digits_count = 0\n",
    "    total_chars = len(domain_lower)\n",
    "\n",
    "    # Iterate through the domain characters to count consecutive digits\n",
    "    i = 0\n",
    "    while i < total_chars - 1:\n",
    "        if domain_lower[i].isdigit() and domain_lower[i + 1].isdigit():\n",
    "            consecutive_digits_count += 1\n",
    "            # Skip to the next non-digit character\n",
    "            while i < total_chars - 1 and domain_lower[i].isdigit():\n",
    "                i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "    print(consecutive_digits_count)\n",
    "    # Calculate the ratio of consecutive digits\n",
    "    consecutive_digits_ratio = consecutive_digits_count / total_chars if total_chars > 0 else 0\n",
    "\n",
    "    return consecutive_digits_ratio\n",
    "\n",
    "def count_underscore(domain):\n",
    "    underscore_count = 0\n",
    "\n",
    "    for char in domain:\n",
    "        if char == '_':  \n",
    "            underscore_count += 1  \n",
    "\n",
    "    return underscore_count\n",
    "\n",
    "def get_feature_rich_row(domain):\n",
    "    features = {}\n",
    "\n",
    "    # Split the domain into subdomains and TLD (Top-Level Domain)\n",
    "    ext = tldextract.extract(domain)\n",
    "    \n",
    "    # Full domain\n",
    "    #features['full_domain'] = domain\n",
    "    \n",
    "    # Top-Level Domain\n",
    "    features['tld'] = ext.suffix if ext.suffix else 'not_present'    \n",
    "\n",
    "    features['has_tld'] = 1 if ext.suffix else 0\n",
    "    \n",
    "    # Domain and Subdomain lengths\n",
    "    features['full_domain_length'] = len(domain)\n",
    "    features['domain_length'] = len(ext.domain)\n",
    "    \n",
    "    # Check if the domain has a subdomain\n",
    "    features['has_subdomain'] = 1 if ext.subdomain else 0\n",
    "\n",
    "    features['subdomain_length'] = len(ext.subdomain)\n",
    "\n",
    "    #Calculating the number of subdomains\n",
    "    features['subdomains_count'] = count_number_of_subdomains(ext)\n",
    "    \n",
    "    #Calculating the average length of subdomains\n",
    "    features['avg_subdomain_length'] = calculate_average_subdomain_length(ext)\n",
    "    \n",
    "    #Calculating the entropy of the domain name\n",
    "    features['entropy_of_domain'] = calculate_entropy(domain)\n",
    "    \n",
    "    #Caluclating the average entropy of subdomains\n",
    "    features['avg_entropy_of_subdomains'] = calculate_average_entropy_of_subdomains(ext)\n",
    "    \n",
    "    #Calculating the ratio of alphanumeric characters in the domain name\n",
    "    features['alphanumeric_ratio'] = calculate_alphanumeric_ratio(domain)\n",
    "    \n",
    "    #calculating the ratio of numeric characters in the domain name\n",
    "    features['numeric_ratio'] = calculate_numeric_ratio(domain)\n",
    "    \n",
    "    #Calculating the ratio of special characters in the domain name\n",
    "    features['special_char_ratio'] = calculate_special_char_ratio(domain)\n",
    "\n",
    "    features['underscore_ratio'] = domain.count('_') / len(domain)\n",
    "\n",
    "    number_of_digits = count_digits(domain)\n",
    "\n",
    "    features['contains_digit']  = 1 if number_of_digits > 0 else 0\n",
    "\n",
    "    length = double(len(ext.domain) +len(ext.subdomain))\n",
    "    \n",
    "    features['digit_ratio'] = number_of_digits / length if length > 0 else 0.0\n",
    "\n",
    "    features['hyphen_ratio'] = (count_hyphens(domain)) / length if length > 0 else 0.0\n",
    "\n",
    "    features['underscore_ratio'] = (count_underscore(domain))/ length if length > 0 else 0.0\n",
    "\n",
    "    features['vowel_ratio'] =  (count_vowels(domain))/ length if length > 0 else 0.0\n",
    "\n",
    "    features['repeated_chars_ratio'] = calculate_repeated_chars_ratio(ext.domain)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    domain_name = row['domain_name']\n",
    "    label = row['label']\n",
    "    feature_rich_row = get_feature_rich_row(domain_name)\n",
    "    feature_rich_row['label'] = label\n",
    "    dataset.append(feature_rich_row)\n",
    "\n",
    "dataset_df = pd.DataFrame(dataset)\n",
    "\n",
    "#print(dataset_df)\n",
    "\n",
    "dataset_df.to_csv(r'C:/Users/ashuo/DNS/data/dga_classifier.csv', index=False)\n",
    "\n",
    "df = dataset_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "encoder = ce.BinaryEncoder(cols=['tld'])\n",
    "df = encoder.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39793 entries, 0 to 39792\n",
      "Data columns (total 28 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   tld_0                      39793 non-null  int64  \n",
      " 1   tld_1                      39793 non-null  int64  \n",
      " 2   tld_2                      39793 non-null  int64  \n",
      " 3   tld_3                      39793 non-null  int64  \n",
      " 4   tld_4                      39793 non-null  int64  \n",
      " 5   tld_5                      39793 non-null  int64  \n",
      " 6   tld_6                      39793 non-null  int64  \n",
      " 7   tld_7                      39793 non-null  int64  \n",
      " 8   tld_8                      39793 non-null  int64  \n",
      " 9   has_tld                    39793 non-null  int64  \n",
      " 10  full_domain_length         39793 non-null  int64  \n",
      " 11  domain_length              39793 non-null  int64  \n",
      " 12  has_subdomain              39793 non-null  int64  \n",
      " 13  subdomain_length           39793 non-null  int64  \n",
      " 14  subdomains_count           39793 non-null  float64\n",
      " 15  avg_subdomain_length       39793 non-null  float64\n",
      " 16  entropy_of_domain          39793 non-null  float64\n",
      " 17  avg_entropy_of_subdomains  39793 non-null  float64\n",
      " 18  alphanumeric_ratio         39793 non-null  float64\n",
      " 19  numeric_ratio              39793 non-null  float64\n",
      " 20  special_char_ratio         39793 non-null  float64\n",
      " 21  underscore_ratio           39793 non-null  float64\n",
      " 22  contains_digit             39793 non-null  int64  \n",
      " 23  digit_ratio                39793 non-null  float64\n",
      " 24  hyphen_ratio               39793 non-null  float64\n",
      " 25  vowel_ratio                39793 non-null  float64\n",
      " 26  repeated_chars_ratio       39793 non-null  float64\n",
      " 27  label                      39793 non-null  int64  \n",
      "dtypes: float64(12), int64(16)\n",
      "memory usage: 8.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df.drop('label',axis=1)\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the encoder and scaler to files\n",
    "with open(r'C:/Users/ashuo/DNS/models/dga_tld_encoder.pkl', 'wb') as encoder_file:\n",
    "    pickle.dump(encoder, encoder_file)\n",
    "\n",
    "with open(r'C:/Users/ashuo/DNS/models/dga_feature_scaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming your new input data is in a variable named 'new_data'\n",
    "\n",
    "# # For binary encoding:\n",
    "# new_data_encoded = loaded_encoder.transform(new_data['tld_column'])\n",
    "\n",
    "# # For feature scaling:\n",
    "# scaled_new_features = loaded_scaler.transform(new_data)  # Replace 'new_data' with your input feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "     Accuracy  Precision    Recall   F-Score\n",
      "SVM  0.840181   0.869848  0.791624  0.828894\n",
      "RF   0.840684   0.863234  0.801131  0.831023\n",
      "GBT  0.830004   0.859326  0.780062  0.817778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize models\n",
    "svm_model = SVC()\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "gbt_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train models\n",
    "svm_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "gbt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "gbt_pred = gbt_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "models = [svm_model, rf_model, gbt_model]\n",
    "metrics = []\n",
    "\n",
    "for model in models:\n",
    "    accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    precision = precision_score(y_test, model.predict(X_test))\n",
    "    recall = recall_score(y_test, model.predict(X_test))\n",
    "    f1 = f1_score(y_test, model.predict(X_test))\n",
    "    metrics.append([accuracy, precision, recall, f1])\n",
    "\n",
    "# Create a DataFrame for the table\n",
    "results_df = pd.DataFrame(metrics, columns=['Accuracy', 'Precision', 'Recall', 'F-Score'], index=['SVM', 'RF', 'GBT'])\n",
    "\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved models\n",
    "with open(r'C:/Users/ashuo/DNS/models/dga_svm_model.pkl', 'wb') as svm_file:\n",
    "    pickle.dump(svm_model, svm_file)\n",
    "\n",
    "with open(r'C:/Users/ashuo/DNS/models/dga_rf_model.pkl', 'wb') as rf_file:\n",
    "    pickle.dump(rf_model, rf_file)\n",
    "\n",
    "with open(r'C:/Users/ashuo/DNS/models/dga_gbt_model.pkl', 'wb') as gbt_file:\n",
    "    pickle.dump(gbt_model, gbt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
